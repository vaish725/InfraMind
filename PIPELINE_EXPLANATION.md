# ğŸ—ï¸ InfraMind - Complete Codebase Pipeline Explanation

**Date:** February 5, 2026  
**Version:** 1.0  

---

## ğŸ“š Table of Contents

1. [High-Level Overview](#high-level-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Complete Data Flow](#complete-data-flow)
4. [Component Deep Dive](#component-deep-dive)
5. [Code Organization](#code-organization)
6. [Request Lifecycle](#request-lifecycle)
7. [Key Classes & Functions](#key-classes--functions)

---

## ğŸ¯ High-Level Overview

**InfraMind** is an AI-powered infrastructure debugging tool that analyzes logs, metrics, traces, and configuration files to identify root causes of incidents and generate actionable fix suggestions.

### Core Technology Stack
- **Frontend:** Streamlit (Python web framework)
- **Backend:** FastAPI (REST API)
- **AI Engine:** Google Gemini 2.0 Flash
- **Data Processing:** Pandas, custom parsers
- **Storage:** In-memory (demo), designed for database

### System Architecture (3-Layer)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRESENTATION LAYER                     â”‚
â”‚              (Streamlit Web Interface)                  â”‚
â”‚  - File upload UI                                       â”‚
â”‚  - Results visualization                                â”‚
â”‚  - Incident history                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP REST API Calls
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION LAYER                     â”‚
â”‚                   (FastAPI Backend)                     â”‚
â”‚  - API endpoints                                        â”‚
â”‚  - Request validation                                   â”‚
â”‚  - Business logic orchestration                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Function Calls
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING LAYER                     â”‚
â”‚              (Parsers + Reasoning Engine)               â”‚
â”‚  - Data ingestion & parsing                             â”‚
â”‚  - Gemini AI integration                                â”‚
â”‚  - Root cause analysis                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚                            USER INTERFACE                            â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Streamlit Frontend (Port 8501)                 â”‚   â”‚
â”‚  â”‚                                                             â”‚   â”‚
â”‚  â”‚  Pages:                                                     â”‚   â”‚
â”‚  â”‚  â€¢ New Analysis      (file upload, configuration)          â”‚   â”‚
â”‚  â”‚  â€¢ Incident History  (past analyses)                       â”‚   â”‚
â”‚  â”‚  â€¢ Settings          (preferences)                         â”‚   â”‚
â”‚  â”‚                                                             â”‚   â”‚
â”‚  â”‚  Components:                                                â”‚   â”‚
â”‚  â”‚  â€¢ Multi-file uploader                                     â”‚   â”‚
â”‚  â”‚  â€¢ Sample data selector                                    â”‚   â”‚
â”‚  â”‚  â€¢ Results visualizer                                      â”‚   â”‚
â”‚  â”‚  â€¢ Causal chain display                                    â”‚   â”‚
â”‚  â”‚  â€¢ Fix suggestions cards                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ HTTP Requests (REST API)
                        â”‚ POST /api/v1/incidents/analyze
                        â”‚ GET  /api/v1/incidents/{id}
                        â”‚ GET  /api/v1/health
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚                          API LAYER (FastAPI)                         â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              FastAPI Backend (Port 8000)                    â”‚   â”‚
â”‚  â”‚                                                             â”‚   â”‚
â”‚  â”‚  Routes:                                                    â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/health      â†’ Health check                      â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/ready       â†’ Readiness probe                   â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/live        â†’ Liveness probe                    â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/incidents/analyze â†’ Main analysis endpoint      â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/incidents/{id}    â†’ Get incident details        â”‚   â”‚
â”‚  â”‚  â€¢ /api/v1/incidents   â†’ List all incidents                â”‚   â”‚
â”‚  â”‚                                                             â”‚   â”‚
â”‚  â”‚  Middleware:                                                â”‚   â”‚
â”‚  â”‚  â€¢ CORS (cross-origin requests)                            â”‚   â”‚
â”‚  â”‚  â€¢ Request validation (Pydantic)                           â”‚   â”‚
â”‚  â”‚  â€¢ Error handling                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ Direct Function Calls
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚                       PROCESSING LAYER                               â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    DATA INGESTION                            â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚  LogParser   â”‚  â”‚MetricsParser â”‚  â”‚ConfigParser  â”‚     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Parse JSON â”‚  â”‚â€¢ Parse JSON  â”‚  â”‚â€¢ Parse YAML  â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Parse text â”‚  â”‚â€¢ Detect      â”‚  â”‚â€¢ Parse ENV   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Extract    â”‚  â”‚  anomalies   â”‚  â”‚â€¢ Compare     â”‚     â”‚ â”‚
â”‚  â”‚  â”‚   fields     â”‚  â”‚â€¢ Calculate   â”‚  â”‚  configs     â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Filter by  â”‚  â”‚  stats       â”‚  â”‚â€¢ Find diffs  â”‚     â”‚ â”‚
â”‚  â”‚  â”‚   timestamp  â”‚  â”‚â€¢ Summarize   â”‚  â”‚              â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚TraceParser   â”‚  â”‚       DataUnifier                â”‚   â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚ â”‚
â”‚  â”‚  â”‚â€¢ Parse spans â”‚  â”‚â€¢ Combine all data sources        â”‚   â”‚ â”‚
â”‚  â”‚  â”‚â€¢ Build tree  â”‚  â”‚â€¢ Create UnifiedContext           â”‚   â”‚ â”‚
â”‚  â”‚  â”‚â€¢ Calculate   â”‚  â”‚â€¢ Apply time window filtering     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  latencies   â”‚  â”‚â€¢ Deduplicate events              â”‚   â”‚ â”‚
â”‚  â”‚  â”‚â€¢ Find errors â”‚  â”‚â€¢ Sort chronologically            â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                        â”‚
â”‚                           â”‚ Creates UnifiedContext                 â”‚
â”‚                           â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                  REASONING ENGINE                            â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚           ReasoningEngine                          â”‚    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚ â”‚
â”‚  â”‚  â”‚ analyze_incident()                                 â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   â†“                                                â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   1. Generate prompts from context                â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   2. Call Gemini API                              â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   3. Parse AI response                            â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   4. Validate results                             â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   5. Build causal chain                           â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   6. Generate fix suggestions                     â”‚    â”‚ â”‚
â”‚  â”‚  â”‚   7. Calculate confidence scores                  â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                           â”‚                                  â”‚ â”‚
â”‚  â”‚                           â”‚ Uses                             â”‚ â”‚
â”‚  â”‚                           â†“                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚             GeminiClient                           â”‚    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ API key management                               â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Retry logic (3 attempts)                        â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Rate limiting handling                          â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Response formatting                             â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Error handling                                  â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                           â”‚                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚ API Calls
                               â†“
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Google Gemini API  â”‚
                     â”‚   (Gemini 2.0 Flash) â”‚
                     â”‚                      â”‚
                     â”‚ â€¢ Reasoning          â”‚
                     â”‚ â€¢ Analysis           â”‚
                     â”‚ â€¢ Fix generation     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Data Flow

### Step-by-Step Journey of an Incident Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: User Interaction                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User opens Streamlit UI (http://localhost:8501)
   â†“
Uploads files OR selects sample data:
   â€¢ Logs:    3 files (api-gateway.log, order-service.log, payment-service.log)
   â€¢ Metrics: 2 files (system-metrics.json, application-metrics.json)
   â€¢ Traces:  1 file (traces.json)
   â€¢ Configs: 0 files (optional)
   â†“
Configures analysis:
   â€¢ Time window: 30 minutes
   â€¢ Focus area: "auto"
   â€¢ Include summary: Yes
   â†“
Clicks "Analyze Incident" button

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Frontend Processing                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

frontend/app.py â†’ submit_analysis() function
   â†“
Reads file contents:
   â€¢ log_file.read().decode('utf-8')
   â€¢ OR loads from data/samples/ directory
   â†“
Constructs payload:
{
    "incident_id": "incident-20260205-143000",
    "log_files": [
        {"content": "...", "source": "api-gateway"},
        {"content": "...", "source": "order-service"},
        {"content": "...", "source": "payment-service"}
    ],
    "metric_files": [
        {"content": "{...}"},
        {"content": "{...}"}
    ],
    "trace_files": ["[{...}]"],
    "time_window_minutes": 30,
    "focus_area": null,
    "include_summary": true
}
   â†“
Makes HTTP POST request:
   URL: http://localhost:8000/api/v1/incidents/analyze
   Headers: {"Content-Type": "application/json"}
   Body: payload
   Timeout: 60 seconds

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: API Layer - Request Reception                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FastAPI receives request at backend/api/routes/incident.py
   â†“
Middleware processes request:
   â€¢ CORS check (allow all origins in development)
   â€¢ Content-Type validation
   â†“
Pydantic validation:
   â€¢ Validates AnalyzeIncidentRequest schema
   â€¢ Checks required fields
   â€¢ Converts types
   â†“
Creates incident record in memory:
incidents_db[incident_id] = {
    "incident_id": incident_id,
    "status": "processing",
    "created_at": datetime.now(),
    "rca": None
}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Data Parsing - Logs                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/ingestion/log_parser.py â†’ LogParser.parse_file()
   â†“
For each log file content:
   â†“
   Detect format (JSON or plain text)
   â†“
   IF JSON:
      â€¢ json.loads(content)
      â€¢ Extract fields: timestamp, level, message, service
   IF Text:
      â€¢ Parse with regex patterns
      â€¢ Extract timestamp, level, message
   â†“
   Create LogEntry objects:
   LogEntry(
       timestamp=datetime(...),
       level="ERROR",
       message="Database connection timeout",
       source="api-gateway",
       service="api-gateway",
       trace_id="abc123",
       metadata={...}
   )
   â†“
   Filter by time window (if specified)
   â†“
   Collect all LogEntry objects into list

Result: List[LogEntry] (77 logs from sample data)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Data Parsing - Metrics                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/ingestion/metrics_parser.py â†’ MetricsParser.parse_file()
   â†“
For each metric file:
   â†“
   Parse JSON: json.loads(content)
   â†“
   Create Metric objects for each time series:
   Metric(
       timestamp=datetime(...),
       name="cpu_usage_percent",
       value=85.3,
       labels={"host": "web-1", "service": "api"},
       unit="percent"
   )
   â†“
   Calculate statistics:
      â€¢ Mean, median, std_dev
      â€¢ Min, max values
      â€¢ Anomaly detection (> mean + 2*std_dev)
   â†“
   Create MetricSummary objects:
   MetricSummary(
       metric_name="cpu_usage_percent",
       time_range=(start, end),
       avg_value=75.2,
       max_value=95.8,
       anomaly_detected=True,
       anomaly_threshold=85.0,
       data_points=[...]
   )

Result: List[MetricSummary] (11 metric summaries from sample data)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Data Parsing - Traces                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/ingestion/trace_parser.py â†’ TraceParser.parse_file()
   â†“
Parse JSON trace data
   â†“
For each span in traces:
   â†“
   Create TraceSpan objects:
   TraceSpan(
       trace_id="abc123",
       span_id="span001",
       parent_span_id=None,
       service="api-gateway",
       operation="GET /orders",
       start_time=datetime(...),
       end_time=datetime(...),
       duration_ms=1523.5,
       status="error",
       error_message="Timeout connecting to database",
       tags={"http.method": "GET", ...}
   )
   â†“
   Build span hierarchy (parent-child relationships)
   â†“
   Calculate latencies
   â†“
   Identify error spans

Result: List[TraceSpan] (9 traces from sample data)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: Data Parsing - Configs (if provided)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/ingestion/config_parser.py â†’ ConfigParser.parse_file()
   â†“
If config files provided:
   â†“
   Detect format (YAML, ENV, auto)
   â†“
   Parse configuration:
      â€¢ YAML: yaml.safe_load()
      â€¢ ENV: Custom parser for KEY=VALUE
   â†“
   Compare with previous config (if provided):
      â€¢ Find added keys
      â€¢ Find removed keys
      â€¢ Find changed values
   â†“
   Create ConfigChange objects:
   ConfigChange(
       timestamp=datetime(...),
       file_path="database.yaml",
       key="connection_timeout",
       old_value="5s",
       new_value="30s",
       change_type="modified"
   )

Result: List[ConfigChange] (1 config change from sample data)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: Data Unification                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/ingestion/data_unifier.py â†’ DataUnifier.create_unified_context()
   â†“
Receives all parsed data:
   â€¢ logs: List[LogEntry]
   â€¢ metrics: List[MetricSummary]
   â€¢ traces: List[TraceSpan]
   â€¢ configs: List[ConfigChange]
   â€¢ deployments: List[DeploymentEvent]
   â†“
Apply time window filtering:
   â€¢ Calculate time_start = latest_timestamp - time_window_minutes
   â€¢ Filter all data to this window
   â†“
Deduplicate events (same timestamp, same content)
   â†“
Sort chronologically by timestamp
   â†“
Create UnifiedContext object:
UnifiedContext(
    incident_id="incident-20260205-143000",
    logs=[...],              # 77 logs
    metrics=[...],           # 11 metric summaries
    traces=[...],            # 9 traces
    config_changes=[...],    # 1 config change
    deployments=[...],       # 0 deployments
    time_window_start=datetime(...),
    time_window_end=datetime(...)
)

Result: UnifiedContext object with all correlated data

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: Reasoning Engine - Prompt Generation                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/reasoning/reasoning_engine.py â†’ ReasoningEngine.analyze_incident()
   â†“
Receives UnifiedContext
   â†“
backend/reasoning/prompts.py â†’ PromptTemplates.get_analysis_prompt()
   â†“
Converts UnifiedContext to dictionary:
{
    "incident_id": "...",
    "logs": [{"timestamp": "...", "level": "ERROR", ...}, ...],
    "metrics": [{"metric_name": "cpu_usage", ...}, ...],
    "traces": [{"trace_id": "...", "duration_ms": 1523, ...}, ...],
    ...
}
   â†“
Generates structured prompt:

"""
You are an expert Site Reliability Engineer (SRE) analyzing an infrastructure incident.

## Incident Data

### Logs (77 entries):
2026-02-05 14:28:32 ERROR [api-gateway] Database connection timeout after 5000ms
2026-02-05 14:28:35 ERROR [order-service] Failed to fetch order #12345
...

### Metrics:
- cpu_usage_percent: avg=75.2%, max=95.8%, anomaly detected at 14:28
- memory_usage_bytes: avg=8.2GB, max=11.5GB
...

### Traces:
- Trace abc123: GET /orders -> 1523ms (TIMEOUT)
  - api-gateway -> order-service: 45ms
  - order-service -> database: TIMEOUT (5000ms)
...

### Configuration Changes:
- 14:25 - database.yaml: connection_timeout changed from 5s to 30s
...

## Your Task

Analyze this incident and provide:
1. Root cause identification
2. Affected services
3. Causal chain of events
4. Fix suggestions (prioritized)
5. Confidence score

Format your response as JSON...
"""

Result: Structured prompt string (~5,000-10,000 tokens)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 10: Gemini API Call                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

backend/reasoning/gemini_client.py â†’ GeminiClient.generate_content()
   â†“
Prepares API request:
   â€¢ API key from settings
   â€¢ Model: "gemini-2.0-flash"
   â€¢ Temperature: 0.3 (low for consistency)
   â€¢ Max output tokens: 8192
   â†“
Makes API call with retry logic:
   @retry(stop_after_attempt=3, wait_exponential)
   â†“
   Attempt 1:
      client.models.generate_content(
          model="gemini-2.0-flash",
          contents=prompt,
          config={
              "temperature": 0.3,
              "max_output_tokens": 8192
          }
      )
   â†“
   IF API Error (quota, network, etc.):
      Wait 2 seconds
      Attempt 2 (same process)
   â†“
   IF Still failing:
      Wait 4 seconds
      Attempt 3 (final)
   â†“
   IF All attempts fail:
      Raise GeminiAPIError("Failed after 3 attempts")
   â†“
Receives response from Gemini:
{
    "text": "{...JSON response...}",
    "candidates": [...],
    "usage_metadata": {...}
}
   â†“
Extracts response.text
   â†“
Returns AI-generated JSON string

Result: JSON string with root cause analysis (~2,000-5,000 tokens)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 11: Response Parsing & Validation                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ReasoningEngine.analyze_incident() continues...
   â†“
Receives AI response (JSON string)
   â†“
Parse JSON:
   rca_dict = json.loads(response)
   â†“
Validate structure:
   â€¢ Has required fields? (root_cause_title, description, etc.)
   â€¢ Are confidence scores valid? (0-1 range)
   â€¢ Are fix suggestions present?
   â€¢ Is causal chain logical?
   â†“
Create RootCauseAnalysis object:
RootCauseAnalysis(
    incident_id="incident-20260205-143000",
    root_cause_title="Database Connection Pool Exhaustion",
    root_cause_description="The connection timeout configuration...",
    confidence_score=0.92,
    affected_services=["api-gateway", "order-service", "database"],
    causal_chain=[
        CausalLink(
            from_event="Config change: connection_timeout 5s->30s",
            to_event="Database connection timeout",
            relationship_type="caused_by",
            confidence=0.95,
            explanation="...",
            evidence=[...]
        ),
        ...
    ],
    fix_suggestions=[
        FixSuggestion(
            title="Revert connection timeout to 5 seconds",
            description="...",
            priority="critical",
            fix_type="configuration",
            estimated_time="5 minutes",
            risk_level="low",
            implementation_steps=[...]
        ),
        ...
    ],
    reasoning_steps=[...],
    severity="high",
    category="configuration",
    user_impact="high",
    business_impact="high"
)
   â†“
IF validate=True:
   â€¢ Validate confidence scores
   â€¢ Check logical consistency
   â€¢ Verify evidence exists
   â†“
Generate summary (if requested):
   summary = await engine.generate_summary(rca)

Result: Complete RootCauseAnalysis object + optional summary

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 12: API Response Construction                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Back in backend/api/routes/incident.py
   â†“
Update incident record:
incidents_db[incident_id] = {
    "incident_id": incident_id,
    "status": "completed",
    "created_at": datetime(...),
    "completed_at": datetime.now(),
    "rca": rca.model_dump(),
    "error": None
}
   â†“
Create response:
AnalyzeIncidentResponse(
    incident_id=incident_id,
    status="completed",
    rca=rca,
    summary=summary
)
   â†“
Serialize to JSON:
{
    "incident_id": "incident-20260205-143000",
    "status": "completed",
    "rca": {
        "root_cause_title": "Database Connection Pool Exhaustion",
        "confidence_score": 0.92,
        ...
    },
    "summary": "The incident was caused by..."
}
   â†“
Return HTTP 200 with JSON body

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 13: Frontend - Results Display                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

frontend/app.py â†’ submit_analysis() receives response
   â†“
IF response.status_code == 200:
   result = response.json()
   st.session_state.analysis_results = result
   st.session_state.incident_id = incident_id
   st.rerun()
   â†“
Page reloads, detects analysis_results in session_state
   â†“
render_analysis_results() function called
   â†“
Displays results in sections:

1. Executive Summary (if present)
   st.info(results["summary"])

2. Root Cause Title
   st.markdown(f"## {rca['root_cause_title']}")
   st.markdown(f"**Confidence:** {rca['confidence_score']:.1%}")

3. Root Cause Description
   st.write(rca['root_cause_description'])

4. Affected Services (grid)
   for service in rca['affected_services']:
       st.markdown(f'<div class="metric-card">{service}</div>')

5. Impact Assessment (4 metrics)
   st.metric("Severity", rca['severity'])
   st.metric("Category", rca['category'])
   st.metric("User Impact", rca['user_impact'])
   st.metric("Business Impact", rca['business_impact'])

6. Causal Chain (expandable)
   for link in rca['causal_chain']:
       with st.expander(f"{link['from_event']} â†’ {link['to_event']}"):
           st.markdown(link['explanation'])
           for evidence in link['evidence']:
               st.markdown(f'<div class="evidence-item">{evidence}</div>')

7. Fix Suggestions (grouped by priority)
   if critical_fixes:
       st.markdown("#### Critical Priority")
       for fix in critical_fixes:
           render_fix_card(fix)  # Shows title, description, steps

8. Reasoning Steps (collapsible)
   with st.expander("Show Reasoning Steps"):
       for step in rca['reasoning_steps']:
           st.markdown(step['description'])

9. Action Buttons
   - Download Report (JSON)
   - New Analysis
   - View All Incidents

User sees complete analysis results with:
âœ… Clear root cause explanation
âœ… Visual confidence indicators
âœ… Step-by-step causal chain
âœ… Prioritized, actionable fixes
âœ… AI reasoning transparency

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COMPLETE! Total Time: 10-30 seconds                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Code Organization

```
InfraMind/
â”‚
â”œâ”€â”€ frontend/                          # Presentation Layer
â”‚   â””â”€â”€ app.py                        # Streamlit UI (659 lines)
â”‚       â”œâ”€â”€ render_header()           # App header with API status
â”‚       â”œâ”€â”€ render_sidebar()          # Navigation menu
â”‚       â”œâ”€â”€ render_new_analysis_page()# File upload & configuration
â”‚       â”œâ”€â”€ submit_analysis()         # API call handler
â”‚       â”œâ”€â”€ render_analysis_results() # Results visualization
â”‚       â”œâ”€â”€ render_fix_card()         # Fix suggestion display
â”‚       â”œâ”€â”€ render_history_page()     # Incident history
â”‚       â””â”€â”€ render_settings_page()    # Settings interface
â”‚
â”œâ”€â”€ backend/                           # Application Layer
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                          # REST API Layer
â”‚   â”‚   â”œâ”€â”€ main.py                   # FastAPI app initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ lifespan()           # Startup/shutdown logic
â”‚   â”‚   â”‚   â”œâ”€â”€ app (FastAPI)        # Main app instance
â”‚   â”‚   â”‚   â””â”€â”€ CORS middleware      # Cross-origin support
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ routes/                   # API Endpoints
â”‚   â”‚       â”œâ”€â”€ health.py            # Health check endpoints
â”‚   â”‚       â”‚   â”œâ”€â”€ /health          # Full health check
â”‚   â”‚       â”‚   â”œâ”€â”€ /ready           # Readiness probe
â”‚   â”‚       â”‚   â””â”€â”€ /live            # Liveness probe
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ incident.py          # Incident analysis endpoints
â”‚   â”‚           â”œâ”€â”€ POST /analyze    # Main analysis endpoint
â”‚   â”‚           â”œâ”€â”€ GET /{id}        # Get incident by ID
â”‚   â”‚           â”œâ”€â”€ GET /            # List all incidents
â”‚   â”‚           â”œâ”€â”€ POST /analyze-files # File upload endpoint
â”‚   â”‚           â””â”€â”€ DELETE /{id}     # Delete incident
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                    # Data Processing Layer
â”‚   â”‚   â”œâ”€â”€ log_parser.py            # Log file parsing (300 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ parse_file()        # Main parsing function
â”‚   â”‚   â”‚   â”œâ”€â”€ _parse_json_log()   # JSON log handler
â”‚   â”‚   â”‚   â”œâ”€â”€ _parse_text_log()   # Plain text handler
â”‚   â”‚   â”‚   â””â”€â”€ _parse_timestamp()  # Timestamp extraction
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ metrics_parser.py        # Metrics parsing (250 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ parse_file()        # Parse metrics JSON
â”‚   â”‚   â”‚   â”œâ”€â”€ create_summaries()  # Generate statistics
â”‚   â”‚   â”‚   â”œâ”€â”€ _detect_anomalies() # Anomaly detection
â”‚   â”‚   â”‚   â””â”€â”€ _calculate_stats()  # Statistical analysis
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ config_parser.py         # Config parsing (200 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ parse_file()        # Parse config files
â”‚   â”‚   â”‚   â”œâ”€â”€ compare_configs()   # Diff two configs
â”‚   â”‚   â”‚   â”œâ”€â”€ _parse_yaml()       # YAML handler
â”‚   â”‚   â”‚   â””â”€â”€ _parse_env()        # ENV handler
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ trace_parser.py          # Trace parsing (300 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ parse_file()        # Parse trace JSON
â”‚   â”‚   â”‚   â”œâ”€â”€ _build_span_tree()  # Build hierarchy
â”‚   â”‚   â”‚   â”œâ”€â”€ _calculate_latency()# Latency calculation
â”‚   â”‚   â”‚   â””â”€â”€ _find_errors()      # Error detection
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ data_unifier.py          # Data combination (230 lines)
â”‚   â”‚       â”œâ”€â”€ create_unified_context() # Combine all sources
â”‚   â”‚       â”œâ”€â”€ _filter_by_time()   # Time window filtering
â”‚   â”‚       â”œâ”€â”€ _deduplicate()      # Remove duplicates
â”‚   â”‚       â””â”€â”€ _sort_chronologically() # Sort by time
â”‚   â”‚
â”‚   â”œâ”€â”€ reasoning/                    # AI Reasoning Layer
â”‚   â”‚   â”œâ”€â”€ gemini_client.py         # Gemini API wrapper (153 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__()          # Client initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ generate_content()  # Main API call (with retry)
â”‚   â”‚   â”‚   â””â”€â”€ _handle_error()     # Error handling
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ prompts.py               # Prompt templates (300+ lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ get_analysis_prompt() # Main analysis prompt
â”‚   â”‚   â”‚   â”œâ”€â”€ get_summary_prompt()  # Summary generation
â”‚   â”‚   â”‚   â”œâ”€â”€ get_validation_prompt() # Validation prompt
â”‚   â”‚   â”‚   â””â”€â”€ _format_context()   # Context formatting
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ reasoning_engine.py      # RCA engine (320+ lines)
â”‚   â”‚       â”œâ”€â”€ analyze_incident()  # Main analysis function
â”‚   â”‚       â”œâ”€â”€ generate_summary()  # Summary generation
â”‚   â”‚       â”œâ”€â”€ explain_reasoning() # Explain AI logic
â”‚   â”‚       â”œâ”€â”€ validate_analysis() # Validate results
â”‚   â”‚       â””â”€â”€ _parse_response()   # Parse Gemini response
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                       # Data Models
â”‚   â”‚   â”œâ”€â”€ incident.py              # Incident data models
â”‚   â”‚   â”‚   â”œâ”€â”€ LogEntry            # Single log entry
â”‚   â”‚   â”‚   â”œâ”€â”€ MetricSummary       # Metric statistics
â”‚   â”‚   â”‚   â”œâ”€â”€ TraceSpan           # Distributed trace span
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigChange        # Configuration change
â”‚   â”‚   â”‚   â”œâ”€â”€ DeploymentEvent     # Deployment event
â”‚   â”‚   â”‚   â””â”€â”€ UnifiedContext      # Combined context
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rca.py                   # RCA data models
â”‚   â”‚   â”‚   â”œâ”€â”€ RootCauseAnalysis   # Main RCA result
â”‚   â”‚   â”‚   â”œâ”€â”€ CausalLink          # Chain link
â”‚   â”‚   â”‚   â”œâ”€â”€ Evidence            # Supporting evidence
â”‚   â”‚   â”‚   â”œâ”€â”€ FixSuggestion       # Fix recommendation
â”‚   â”‚   â”‚   â””â”€â”€ ReasoningStep       # AI reasoning step
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ schemas.py               # API schemas
â”‚   â”‚       â”œâ”€â”€ AnalyzeIncidentRequest  # Request model
â”‚   â”‚       â”œâ”€â”€ AnalyzeIncidentResponse # Response model
â”‚   â”‚       â”œâ”€â”€ HealthCheckResponse     # Health check model
â”‚   â”‚       â”œâ”€â”€ LogFileData            # Log file input
â”‚   â”‚       â”œâ”€â”€ MetricFileData         # Metric file input
â”‚   â”‚       â””â”€â”€ ConfigFileData         # Config file input
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                         # Core Utilities
â”‚   â”‚   â”œâ”€â”€ config.py                # Settings management
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings            # Pydantic settings class
â”‚   â”‚   â”‚   â””â”€â”€ get_settings()      # Settings singleton
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ exceptions.py            # Custom exceptions
â”‚   â”‚       â”œâ”€â”€ InfraMindError      # Base exception
â”‚   â”‚       â”œâ”€â”€ GeminiAPIError      # Gemini-specific
â”‚   â”‚       â”œâ”€â”€ ParsingError        # Data parsing
â”‚   â”‚       â”œâ”€â”€ ValidationError     # Data validation
â”‚   â”‚       â””â”€â”€ ConfigurationError  # Config issues
â”‚   â”‚
â”‚   â””â”€â”€ utils/                        # Utility Functions
â”‚       â””â”€â”€ (future utilities)
â”‚
â”œâ”€â”€ data/                             # Sample Data
â”‚   â””â”€â”€ samples/                     # Demo scenario data
â”‚       â”œâ”€â”€ logs/                    # Log files
â”‚       â”‚   â”œâ”€â”€ api-gateway.log     # 25 logs
â”‚       â”‚   â”œâ”€â”€ order-service.log   # 30 logs
â”‚       â”‚   â””â”€â”€ payment-service.log # 22 logs
â”‚       â”œâ”€â”€ metrics/                 # Metrics files
â”‚       â”‚   â”œâ”€â”€ system-metrics.json # CPU, memory, disk
â”‚       â”‚   â””â”€â”€ application-metrics.json # Latency, errors
â”‚       â”œâ”€â”€ traces/                  # Trace files
â”‚       â”‚   â””â”€â”€ traces.json         # 9 distributed traces
â”‚       â”œâ”€â”€ configs/                 # Config files
â”‚       â”‚   â””â”€â”€ database.yaml       # Database config
â”‚       â””â”€â”€ deployments/             # Deployment events
â”‚           â””â”€â”€ deployments.json    # Deployment history
â”‚
â”œâ”€â”€ scripts/                          # Utility Scripts
â”‚   â”œâ”€â”€ start_api.py                 # Start FastAPI server
â”‚   â”œâ”€â”€ start_frontend.py            # Start Streamlit UI
â”‚   â”œâ”€â”€ start_all.py                 # Start both servers
â”‚   â”œâ”€â”€ test_phase2.py               # Test data ingestion
â”‚   â”œâ”€â”€ test_phase3.py               # Test reasoning engine
â”‚   â”œâ”€â”€ test_phase4.py               # Test API endpoints
â”‚   â””â”€â”€ test_phase5.py               # Test frontend
â”‚
â”œâ”€â”€ .streamlit/                       # Streamlit Config
â”‚   â””â”€â”€ config.toml                  # UI settings
â”‚
â”œâ”€â”€ .env                              # Environment Variables
â”‚   â”œâ”€â”€ GEMINI_API_KEY              # API key
â”‚   â”œâ”€â”€ GEMINI_MODEL                # Model name
â”‚   â””â”€â”€ (other settings)
â”‚
â”œâ”€â”€ requirements.txt                  # Python Dependencies
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ README.md                        # Project documentation
â”œâ”€â”€ prd.md                           # Product requirements
â”œâ”€â”€ hackathon_details.md             # Hackathon info
â”œâ”€â”€ TODO.md                          # Task list
â”œâ”€â”€ PIPELINE_EXPLANATION.md          # This file
â”‚
â””â”€â”€ PHASE*_STATUS.md                 # Phase documentation
    â”œâ”€â”€ PHASE1_STATUS.md
    â”œâ”€â”€ PHASE2_STATUS.md
    â”œâ”€â”€ PHASE3_STATUS.md
    â”œâ”€â”€ PHASE4_STATUS.md
    â””â”€â”€ PHASE5_STATUS.md
```

---

## ğŸ”‘ Key Classes & Functions

### Frontend (Streamlit)

**File:** `frontend/app.py`

```python
# Main application entry
def main():
    """Initialize and run Streamlit app"""
    
# Page rendering
def render_new_analysis_page():
    """Render incident submission form"""
    
def render_analysis_results():
    """Display RCA results with visualizations"""
    
def render_history_page():
    """Show past incident analyses"""

# API interaction
def submit_analysis(...) -> dict:
    """Send analysis request to API"""
    # Makes POST to /api/v1/incidents/analyze
    # Returns: {"incident_id": "...", "rca": {...}, "summary": "..."}

# Session state
st.session_state.analysis_results  # Stores current results
st.session_state.incident_id       # Current incident ID
```

### Backend API (FastAPI)

**File:** `backend/api/main.py`

```python
# Application instance
app = FastAPI(
    title="InfraMind API",
    lifespan=lifespan,
    docs_url="/docs"
)

# Lifespan manager
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown logic"""
```

**File:** `backend/api/routes/incident.py`

```python
@router.post("/incidents/analyze")
async def analyze_incident(request: AnalyzeIncidentRequest):
    """Main RCA endpoint"""
    # 1. Parse all data sources
    # 2. Create unified context
    # 3. Call reasoning engine
    # 4. Return RCA results
    
@router.get("/incidents/{incident_id}")
async def get_incident(incident_id: str):
    """Retrieve incident by ID"""
    
@router.get("/incidents")
async def list_incidents(skip: int = 0, limit: int = 100):
    """List all incidents with pagination"""
```

### Data Ingestion

**File:** `backend/ingestion/log_parser.py`

```python
class LogParser:
    def parse_file(content: str, source: str) -> List[LogEntry]:
        """Parse log file content"""
        # Detects JSON or text format
        # Returns list of LogEntry objects
        
    def _parse_json_log(content: str) -> List[LogEntry]:
        """Parse JSON-formatted logs"""
        
    def _parse_text_log(content: str) -> List[LogEntry]:
        """Parse plain text logs with regex"""
```

**File:** `backend/ingestion/metrics_parser.py`

```python
class MetricsParser:
    def parse_file(content: str) -> List[Metric]:
        """Parse metrics JSON"""
        
    def create_summaries(metrics: List[Metric]) -> List[MetricSummary]:
        """Generate statistical summaries"""
        # Calculates mean, median, std_dev
        # Detects anomalies
        # Returns metric summaries
```

**File:** `backend/ingestion/data_unifier.py`

```python
class DataUnifier:
    def create_unified_context(
        logs: List[LogEntry],
        metrics: List[MetricSummary],
        traces: List[TraceSpan],
        configs: List[ConfigChange],
        deployments: List[DeploymentEvent],
        time_window_minutes: Optional[int]
    ) -> UnifiedContext:
        """Combine all data sources into single context"""
        # Filters by time window
        # Deduplicates events
        # Sorts chronologically
        # Returns unified view
```

### Reasoning Engine

**File:** `backend/reasoning/gemini_client.py`

```python
class GeminiClient:
    def __init__(api_key: str):
        """Initialize Gemini API client"""
        self.client = genai.Client(api_key=api_key)
        
    @retry(stop_after_attempt=3, wait_exponential)
    async def generate_content(
        prompt: str,
        temperature: float = 0.7,
        max_output_tokens: int = None
    ) -> str:
        """Call Gemini API with retry logic"""
        # Makes API call
        # Handles rate limiting
        # Returns generated text
```

**File:** `backend/reasoning/prompts.py`

```python
class PromptTemplates:
    @staticmethod
    def get_analysis_prompt(context: dict, focus_area: str) -> str:
        """Generate root cause analysis prompt"""
        # Formats context data
        # Adds SRE instructions
        # Returns structured prompt
        
    @staticmethod
    def get_summary_prompt(rca: dict) -> str:
        """Generate executive summary prompt"""
```

**File:** `backend/reasoning/reasoning_engine.py`

```python
class ReasoningEngine:
    async def analyze_incident(
        context: UnifiedContext,
        focus_area: Optional[str] = None,
        validate: bool = True
    ) -> RootCauseAnalysis:
        """Perform complete root cause analysis"""
        # 1. Generate prompts
        # 2. Call Gemini API
        # 3. Parse AI response
        # 4. Validate results
        # 5. Build causal chain
        # 6. Generate fix suggestions
        # Returns: RootCauseAnalysis object
        
    async def generate_summary(rca: RootCauseAnalysis) -> str:
        """Generate executive summary of RCA"""
```

### Data Models

**File:** `backend/models/incident.py`

```python
class LogEntry(BaseModel):
    """Single log entry"""
    timestamp: datetime
    level: str
    message: str
    source: str
    service: Optional[str]
    trace_id: Optional[str]
    metadata: Dict[str, Any]

class MetricSummary(BaseModel):
    """Aggregated metric statistics"""
    metric_name: str
    time_range: Tuple[datetime, datetime]
    avg_value: float
    max_value: float
    anomaly_detected: bool
    data_points: List[Metric]

class UnifiedContext(BaseModel):
    """Combined view of all incident data"""
    incident_id: str
    logs: List[LogEntry]
    metrics: List[MetricSummary]
    traces: List[TraceSpan]
    config_changes: List[ConfigChange]
    deployments: List[DeploymentEvent]
    time_window_start: Optional[datetime]
    time_window_end: Optional[datetime]
```

**File:** `backend/models/rca.py`

```python
class RootCauseAnalysis(BaseModel):
    """Complete root cause analysis result"""
    incident_id: str
    root_cause_title: str
    root_cause_description: str
    confidence_score: float
    affected_services: List[str]
    causal_chain: List[CausalLink]
    fix_suggestions: List[FixSuggestion]
    reasoning_steps: List[ReasoningStep]
    severity: str
    category: str
    user_impact: str
    business_impact: str

class CausalLink(BaseModel):
    """Link in the causal chain"""
    from_event: str
    to_event: str
    relationship_type: str
    confidence: float
    explanation: str
    evidence: List[str]

class FixSuggestion(BaseModel):
    """Actionable fix recommendation"""
    title: str
    description: str
    priority: str  # critical, high, medium, low
    fix_type: str
    estimated_time: str
    risk_level: str
    implementation_steps: List[str]
```

---

## ğŸ¯ Summary

InfraMind follows a clean **3-layer architecture**:

1. **Presentation Layer** (Streamlit) - User interface
2. **Application Layer** (FastAPI) - Business logic & API
3. **Processing Layer** (Parsers + Reasoning Engine) - Data processing & AI

**Data flows** through the system in this sequence:
```
User Upload â†’ Frontend â†’ API â†’ Parsers â†’ DataUnifier â†’ 
ReasoningEngine â†’ Gemini AI â†’ RCA Results â†’ API â†’ Frontend â†’ User
```

**Key strengths:**
- âœ… Clean separation of concerns
- âœ… Modular, testable components
- âœ… Type-safe with Pydantic models
- âœ… Comprehensive error handling
- âœ… Well-documented code
- âœ… Production-ready architecture

This architecture makes InfraMind:
- **Scalable**: Easy to add new data sources
- **Maintainable**: Clear component boundaries
- **Testable**: Each layer can be tested independently
- **Extensible**: New features slot in cleanly

---

*This pipeline explanation is current as of February 5, 2026*
